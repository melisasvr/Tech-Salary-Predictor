# ğŸ’° Tech Salary Predictor

- End-to-end ML project: data generation â†’ cleaning â†’ feature engineering â†’ model training â†’ Streamlit deployment.
Inspired by **Levels.fyi** style compensation data.

> âš ï¸ Uses synthetic data for demonstration. Not intended as financial advice.

---

## ğŸ“ Project Structure

```
salary_predictor/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ salaries.csv          # generated by step 1
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ salary_model.pkl       # trained model (auto-selected best)
â”‚   â”œâ”€â”€ encoders.pkl           # label encoders for categorical features
â”‚   â””â”€â”€ metadata.json          # test metrics + CV results + feature importances
â”œâ”€â”€ generate_data.py           # STEP 1 Â· synthetic Levels.fyi-style dataset
â”œâ”€â”€ preprocessing.py           # STEP 2 Â· data cleaning + feature engineering
â”œâ”€â”€ train.py                   # STEP 3 Â· model training + evaluation
â”œâ”€â”€ app.py                     # STEP 4 Â· Streamlit web app (5 tabs)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Generate a synthetic dataset
```bash
python generate_data.py
# â†’ creates data/salaries.csv (5,000 rows)
```

### 3. Train the model
```bash
python train.py
# â†’ evaluates GradientBoosting, RandomForest, XGBoost via 5-fold CV
# â†’ saves best model to models/salary_model.pkl
# â†’ saves encoders.pkl + metadata.json
```

### 4. Launch the app
```bash
streamlit run app.py
# â†’ opens http://localhost:8501
```

---

## ğŸ–¥ï¸ App Features (5 Tabs)

### ğŸ¯ Predict
Enter your profile (role, location, company tier, education, YOE) and get:
- Estimated total compensation with a confidence range
- Gauge chart showing where you sit on the salary spectrum
- Your percentile vs peers in the same role and tier

### ğŸ’¬ Negotiation Tips
Input your current TC (or leave blank for a new offer) and get:
- Market rate prediction vs your current compensation
- Gap analysis with a suggested opening anchor number (~12% above market)
- Personalised tip cards based on your percentile, tier, YOE, and location
- A ready-to-use negotiation script you can copy and adapt

### âš–ï¸ What-If Comparison
Define up to 4 scenarios (different tiers and locations) against a shared base profile:
- Side-by-side TC predictions with delta vs average
- Bar chart comparing all scenarios
- YOE growth curves showing how the salary gap compounds over your career
- "Key Insight" callout calculating the 5-year earnings difference

### ğŸ“Š Market Explorer
Explore the underlying salary data interactively:
- Filter by role and company tier
- Box plots of total comp distribution
- Scatter plot of experience vs compensation
- Horizontal bar chart of median TC by location

### ğŸ” Model Insights
Understand how the model works:
- Test set metrics: RÂ², MAE, MAPE
- Cross-validation results table across all candidate models
- Feature importance chart showing what drives predictions most

---

## ğŸ”¬ ML Pipeline Details

### Data Features

| Feature | Type | Notes |
|---|---|---|
| `role` | categorical | 10 tech roles |
| `location` | categorical | 10 US cities + Remote |
| `company_tier` | categorical | FAANG / Tier2 / Tier3 / Startup |
| `education` | categorical | Bachelor's / Master's / PhD / Bootcamp / Self-taught |
| `years_of_experience` | numeric | 0â€“25 |
| `seniority_level` | engineered | 1â€“5 score extracted from role title |
| `is_faang` | engineered | binary flag for FAANG companies |
| `is_big_tech` | engineered | binary flag for FAANG or Tier2 |
| `yoe_bucket` | engineered | 5 bins: 0-2 / 3-5 / 6-10 / 11-15 / 15+ |
| `remote_work` | binary | 0 = on-site, 1 = remote |

### Target Variable
- `total_compensation` = base salary + annual bonus + annualized RSU
- **Log-transformed** during training to reduce right skew, then inverse-transformed for predictions

### Models Evaluated
| Model | Notes |
|---|---|
| `GradientBoostingRegressor` | sklearn, always available |
| `RandomForestRegressor` | sklearn, always available |
| `XGBRegressor` | xgboost, used if installed |

Winner selected by **5-fold cross-validated RÂ²**. In testing, XGBoost typically wins with RÂ² â‰ˆ 0.92 and MAPE â‰ˆ 8%.

---

## ğŸ”§ Using Real Data

To swap in real salary data instead of synthetic:

1. Prepare a CSV with these columns:
   `company`, `role`, `location`, `education`, `years_of_experience`,
   `base_salary`, `annual_bonus`, `annual_stock`, `total_compensation`,
   `company_tier`, `remote_work`
2. Save it as `data/salaries.csv`
3. Re-run `python train.py` â€” encoders and model will be rebuilt automatically

Good free sources to try:
- [Kaggle Data Science Salary Survey](https://www.kaggle.com/datasets)
- [Stack Overflow Developer Survey](https://survey.stackoverflow.co/)
- [H1B Salary Disclosure Data](https://www.dol.gov/agencies/eta/foreign-labor/performance) (US government, very accurate for tech)

---

## ğŸ“¦ Dependencies

```
streamlit>=1.32.0
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.4.0
joblib>=1.3.0
plotly>=5.18.0
xgboost>=2.0.0   # optional but recommended
```
---
## ğŸ¤ Contributing
- Contributions are very welcome! If you'd like to collaborate on this project, feel free to:
- Fork the repository and submit a Pull Request
- Open an issue if you find a bug or have a feature idea
- Suggest improvements to the agent pipeline, UI, or documentation
- Share the project with others who might find it useful
- Whether it's a small fix, a new feature, or a completely new idea, all contributions are appreciated.
- Let's build something great together! ğŸš€
